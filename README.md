# üß† LLaMA 3 Assignment Demo

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)
![Ollama](https://img.shields.io/badge/Ollama-000000?style=for-the-badge&logoColor=white)


---

## ‚ö†Ô∏è Note

![Python Version](https://img.shields.io/badge/Python-3.10+-blue?logo=python&logoColor=white)

_This AI server requires Python 3.10 or higher. For best compatibility, use Linux or macOS. Docker is recommended for deployment stability. Good GPUS are recommended._

---

## üöÄ Setup Guide

Launch your own locally-hosted LLaMA 3 server with Ollama and FastAPI:

### 1. **Install Ollama**
[‚Üí Ollama Docs](https://ollama.com/docs)

### 2. **Install dependencies using pip**
```py
 pip install -r requirements.txt
```

### 3. **Run FAST API Server using Uvicorn or by dev.py**
_supports hot reload, but you can remove the flag_
```py
python dev.py
```
